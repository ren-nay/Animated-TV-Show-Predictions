{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3cf1c94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24a241fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapes data from the IMDB search result page\n",
    "#formats data into a list to be returned\n",
    "def getPageData(url):\n",
    "    response = requests.get(url) #gets the web page located at the url\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\") #reads the page's text as parsable html\n",
    "    \n",
    "    #get Titles\n",
    "    #get the text inside the tag that has .lister-item.header class\n",
    "    titles = [a.text for a in soup.select('.lister-item-header')]\n",
    "    \n",
    "    #get unique IDs\n",
    "    #for every div with the ribbonize class\n",
    "    #search through its attributes to find a data-tconst\n",
    "    #get the text in the 'data-tconts'\n",
    "    uniqueId = [a.attrs.get('data-tconst') for a in soup.select('div.ribbonize')]\n",
    "    \n",
    "    #get IMDB Ratings\n",
    "    imdbRatings = []\n",
    "    #find every div with lister-item class\n",
    "    for a in soup.select('div.lister-item'):\n",
    "        #if the div contains a strong tag\n",
    "        if a.find('strong'):\n",
    "            #append the text inside the strong tag to the imdbRatings list\n",
    "            imdbRatings.append(a.find('strong').text)\n",
    "        #if the dif doesn't contain a strong tag\n",
    "        else:\n",
    "            #apppend 'N/A' to the list\n",
    "            imdbRatings.append('N/A')\n",
    "    \n",
    "    #get start and end year of shows\n",
    "    #get the text inside every span with the classes lister-item-year and text-muted-unbold\n",
    "    runYears = [a.text for a in soup.select(\"span.lister-item-year.text-muted.unbold\")]\n",
    "\n",
    "    #get TV maturity rating\n",
    "    tvRatings = []\n",
    "    #for every p tag with text-muted class\n",
    "    for a in soup.select('p.text-muted'):\n",
    "        #check if p contains span tag\n",
    "        if a.find('span'):\n",
    "            #check if span tag has certificate class\n",
    "            if a.find('span', class_='certificate'):\n",
    "                #add the first text contents of the certificate span to the tvRatings list\n",
    "                tvRatings.append(a.select('span.certificate')[0].text)\n",
    "            #if p doesn't contain a span tag\n",
    "            else:\n",
    "                #append 'N/A' to the tvRatings list\n",
    "                tvRatings.append('N/A')\n",
    "                \n",
    "    #get runtime of episodes\n",
    "    runtimes= []          \n",
    "    for a in soup.select('p.text-muted'):\n",
    "        if a.find('span'):\n",
    "            if a.find('span', class_='runtime'):\n",
    "                runtimes.append(a.select('span.runtime')[0].text)\n",
    "            else:\n",
    "                runtimes.append('N/A')\n",
    "    \n",
    "    #get genres of shows\n",
    "    genres = [a.text for a in soup.select(\"span.genre\")]\n",
    "    \n",
    "#Formatting the Data\n",
    "    # create a empty list for storing show information\n",
    "    list = []\n",
    "\n",
    "    # Iterating over shows to extract each shows's details\n",
    "    for index in range(0, len(titles)):\n",
    "        title_string = titles[index]  #Example String: \"\\n3.\\nDon't Hug Me I'm Scared\\n(2022– )\\n\",\n",
    "        show = title_string.split('\\n') #turn string into list, splitting at each '\\n'\n",
    "        tv_show_title = show[2]\n",
    "        \n",
    "        #NOTE: this doesn't properly handle shows that only ran 1 year or shows that have multiple versions ex. \"Yu-Gi-Oh (I) (2000-2006)\" gets the \"(I)\" mixed in with the year data.\n",
    "        years = show[3].split('–') #splits the year data further\n",
    "        startYear = years[0].strip('(') #removes '(' from the start year\n",
    "        endYear = years[-1].strip(')') #gets the last item in the list (for some reason just asking for years[1] was wrong?)\n",
    "\n",
    "        if \"min\" in runtimes[index]:\n",
    "            runtimes[index] = runtimes[index].strip(' min')\n",
    "\n",
    "        showGenres = genres[index].strip()\n",
    "        genreList = showGenres.split(',') #not sure what data format is best for the genres, we can have a string with all genres, or a list of all genres\n",
    "        genreList.pop(0) #gets rid of 'Animation' genre that is always first in the list\n",
    "        \n",
    "        #put the data into each corresponding column\n",
    "        #this order can be changed if we need\n",
    "        data = { \"TV Show Title\": tv_show_title,\n",
    "                \"Unique ID\": uniqueId[index],\n",
    "                \"IMDB Rating\": imdbRatings[index],\n",
    "                \"Start Year\": startYear,\n",
    "                \"End Year\": endYear,\n",
    "                \"TV Rating\": tvRatings[index],\n",
    "                \"Episode Run Time (min)\": runtimes[index],\n",
    "                \"Top Genres\": genreList,               \n",
    "                }\n",
    "        #add this to the end of the overall list \n",
    "        list.append(data)\n",
    "    \n",
    "    return list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "102c58d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adds data to the end of the csv file\n",
    "def appendCSV(list):\n",
    "    #saving the list as dataframe then converting into .csv file\n",
    "    df = pd.DataFrame(list)\n",
    "    #append preexising csv file\n",
    "    df.to_csv('data/imdb_animated_shows.csv', mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "af58a02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checks the shape of the csv file\n",
    "def checkCSV():\n",
    "    #find the csv file at the path and read it as a dataframe\n",
    "    da = pd.read_csv('data/imdb_animated_shows.csv')\n",
    "    #print out the shape of the dataframe\n",
    "    print(\"Current Shape: \", da.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6bce2934",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numberOfPages=45 #after the 39th page, the url format changes\n",
    "                  #its because its going from starting with result 9750 to result 10000\n",
    "                  #so there are actually 45 pages, but we can only automate reading from 39 of them\n",
    "                  #so 6 pages of data will go have to be manually added\n",
    "numberOfPages=39\n",
    "currentPage = 1\n",
    "url = \"https://www.imdb.com/search/title/?title_type=tv_series&release_date=1989-01-01,2022-12-31&genres=animation&count=250&ref_=adv_prv\"\n",
    "\n",
    "#get page 1 data and return a list\n",
    "#saving the list as dataframe\n",
    "df = pd.DataFrame(getPageData(url))\n",
    "\n",
    "#then converting into .csv file\n",
    "#write to new (or write over old) csv file\n",
    "df.to_csv('data/imdb_animated_shows.csv', index=False)\n",
    "\n",
    "checkCSV() #should only have 249 shows\n",
    "\n",
    "while currentPage <= numberOfPages:\n",
    "    #gets the URL of the next page\n",
    "    url = \"https://www.imdb.com/search/title/?title_type=tv_series&release_date=1989-01-01,2022-12-31&genres=animation&count=250&start=\" + str((250*currentPage)+1) + \"&ref_=adv_nxt\"\n",
    "    #get the next page's data and returns it as a formatted list\n",
    "    #the list is apended to the csv file created earlier\n",
    "    appendCSV(getPageData(url))\n",
    "    currentPage += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6c418f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Shape:  (9999, 8)\n"
     ]
    }
   ],
   "source": [
    "checkCSV() #should have 9,999 shows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "270bb894",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the data from the last 5 pages that have special urls\n",
    "appendCSV(getPageData(\"https://www.imdb.com/search/title/?title_type=tv_series&release_date=1989-01-01,2022-12-31&genres=animation&count=250&after=WzE1NjM3MzAsInR0MDQ2MzgwOCIsMTAwMDBd&ref_=adv_nxt\"))\n",
    "appendCSV(getPageData(\"https://www.imdb.com/search/title/?title_type=tv_series&release_date=1989-01-01,2022-12-31&genres=animation&count=250&after=WzE3MTYyNzAsInR0MTU0NjIzMjYiLDEwMjUwXQ%3D%3D&ref_=adv_nxt\"))\n",
    "appendCSV(getPageData(\"https://www.imdb.com/search/title/?title_type=tv_series&release_date=1989-01-01,2022-12-31&genres=animation&count=250&after=WzE4NjA0NTEsInR0NzIzMjk1OCIsMTA1MDBd&ref_=adv_nxt\"))\n",
    "appendCSV(getPageData(\"https://www.imdb.com/search/title/?title_type=tv_series&release_date=1989-01-01,2022-12-31&genres=animation&count=250&after=WzIwMjM1MTEsInR0MTI5MjkzOTQiLDEwNzUwXQ%3D%3D&ref_=adv_nxt\"))\n",
    "appendCSV(getPageData(\"https://www.imdb.com/search/title/?title_type=tv_series&release_date=1989-01-01,2022-12-31&genres=animation&count=250&after=WzIxOTY1NzIsInR0MTAxNDYzMDIiLDExMDAwXQ%3D%3D&ref_=adv_nxt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f57ce9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Shape:  (11147, 8)\n"
     ]
    }
   ],
   "source": [
    "checkCSV() #should have all 11,147 shows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
